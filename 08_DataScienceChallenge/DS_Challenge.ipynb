{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_path = r'../../../data/challenge/bookings.csv.bz2'\n",
    "searches_path = r'../../../data/challenge/searches.csv.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-03aca5c56578>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mzip_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbookings_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\bz2.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_can_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\_compression.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                     \u001b[0mrawblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "zip_file = bz2.BZ2File(bookings_path, 'r')\n",
    "df = zip_file.read()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.BZ2File(bookings_path) as f:\n",
    "    # Decompress data from file\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bookings_path = r'C:\\Users\\Usuario\\Desktop\\Master DATA SCIENCE\\data\\challenge\\bookings.csv'\n",
    "temp = pd.read_csv(bookings_path, sep='delimiter', header=None).head(10000)\n",
    "temp.to_csv('sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_path = r'./sample.csv.bz2'\n",
    "df = pd.read_csv(bookings_path, compression='bz2', sep= '^', header=1, usecols=['arr_port', 'pax', 'year'], nrows = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.columns = [col.strip() for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_path = r'../../../data/challenge/bookings.csv.bz2'\n",
    "df_big = pd.read_csv(\n",
    "                     bookings_path,\n",
    "                     compression='bz2', \n",
    "                     sep= '^', \n",
    "                     header=0, \n",
    "                     usecols=['arr_port', 'pax', 'year'], \n",
    "                     #nrows = 100000\n",
    "                     chunksize=100_000 # con este parametro se convierte en un iterador\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-61891b31b1b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m with pd.read_csv(\n\u001b[0m\u001b[0;32m      2\u001b[0m                      \u001b[0mbookings_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                      \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bz2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                      \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'^'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                      \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: __enter__"
     ]
    }
   ],
   "source": [
    "with pd.read_csv(\n",
    "                     bookings_path,\n",
    "                     compression='bz2', \n",
    "                     sep= '^', \n",
    "                     header=0, \n",
    "                     usecols=['arr_port', 'pax', 'year'], \n",
    "                     #nrows = 100000\n",
    "                     chunksize=100_000 # con este parametro se convierte en un iterador\n",
    "                    ) as df_iter:\n",
    "                    for chunk in df_big:\n",
    "                        print(len(chunk))\n",
    "                        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import bz2\n",
    "\n",
    "import neobase as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_path = r'../../../data/challenge/bookings.csv.bz2'\n",
    "searches_path = r'../../../data/challenge/searches.csv.bz2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since bookings file is 4.4Gb, we could use a sample to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(bookings_path, compression='bz2', sep= '^', header=0, nrows = 100_000)\n",
    "sample.to_csv('../../../data/challenge/sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_date</th>\n",
       "      <th>source</th>\n",
       "      <th>pos_ctry</th>\n",
       "      <th>pos_iata</th>\n",
       "      <th>pos_oid</th>\n",
       "      <th>rloc</th>\n",
       "      <th>cre_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>distance</th>\n",
       "      <th>dep_port</th>\n",
       "      <th>...</th>\n",
       "      <th>route</th>\n",
       "      <th>carrier</th>\n",
       "      <th>bkg_class</th>\n",
       "      <th>cab_class</th>\n",
       "      <th>brd_time</th>\n",
       "      <th>off_time</th>\n",
       "      <th>pax</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>oid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-03-05 00:00:00</td>\n",
       "      <td>1A</td>\n",
       "      <td>DE</td>\n",
       "      <td>a68dd7ae953c8acfb187a1af2dcbe123</td>\n",
       "      <td>1a11ae49fcbf545fd2afc1a24d88d2b7</td>\n",
       "      <td>ea65900e72d71f4626378e2ebd298267</td>\n",
       "      <td>2013-02-22 00:00:00</td>\n",
       "      <td>1708</td>\n",
       "      <td>0</td>\n",
       "      <td>ZRH</td>\n",
       "      <td>...</td>\n",
       "      <td>LHRZRH</td>\n",
       "      <td>VI</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-03-07 08:50:00</td>\n",
       "      <td>2013-03-07 11:33:37</td>\n",
       "      <td>-1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-26 00:00:00</td>\n",
       "      <td>1A</td>\n",
       "      <td>US</td>\n",
       "      <td>e612b9eeeee6f17f42d9b0d3b79e75ca</td>\n",
       "      <td>7437560d8f276d6d05eeb806d9e7edee</td>\n",
       "      <td>737295a86982c941f1c2da9a46a14043</td>\n",
       "      <td>2013-03-26 00:00:00</td>\n",
       "      <td>135270</td>\n",
       "      <td>0</td>\n",
       "      <td>SAL</td>\n",
       "      <td>...</td>\n",
       "      <td>SALATLCLT</td>\n",
       "      <td>NV</td>\n",
       "      <td>L</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-04-12 13:04:00</td>\n",
       "      <td>2013-04-12 22:05:40</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-26 00:00:00</td>\n",
       "      <td>1A</td>\n",
       "      <td>US</td>\n",
       "      <td>e612b9eeeee6f17f42d9b0d3b79e75ca</td>\n",
       "      <td>7437560d8f276d6d05eeb806d9e7edee</td>\n",
       "      <td>737295a86982c941f1c2da9a46a14043</td>\n",
       "      <td>2013-03-26 00:00:00</td>\n",
       "      <td>135270</td>\n",
       "      <td>0</td>\n",
       "      <td>SAL</td>\n",
       "      <td>...</td>\n",
       "      <td>CLTATLSAL</td>\n",
       "      <td>NV</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-07-15 07:00:00</td>\n",
       "      <td>2013-07-15 11:34:51</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-03-26 00:00:00</td>\n",
       "      <td>1A</td>\n",
       "      <td>AU</td>\n",
       "      <td>0f984b3bb6bd06661c95529bbd6193bc</td>\n",
       "      <td>36472c6dbaf7afec9136ac40364e2794</td>\n",
       "      <td>5ecf00fdcbcec761c43dc7285253d0c1</td>\n",
       "      <td>2013-03-26 00:00:00</td>\n",
       "      <td>30885</td>\n",
       "      <td>0</td>\n",
       "      <td>AKL</td>\n",
       "      <td>...</td>\n",
       "      <td>AKLHKGSVO</td>\n",
       "      <td>XK</td>\n",
       "      <td>G</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-04-24 23:59:00</td>\n",
       "      <td>2013-04-25 16:06:31</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>SYDA82546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-03-26 00:00:00</td>\n",
       "      <td>1A</td>\n",
       "      <td>AU</td>\n",
       "      <td>0f984b3bb6bd06661c95529bbd6193bc</td>\n",
       "      <td>36472c6dbaf7afec9136ac40364e2794</td>\n",
       "      <td>5ecf00fdcbcec761c43dc7285253d0c1</td>\n",
       "      <td>2013-03-26 00:00:00</td>\n",
       "      <td>30885</td>\n",
       "      <td>0</td>\n",
       "      <td>AKL</td>\n",
       "      <td>...</td>\n",
       "      <td>SVOHKGAKL</td>\n",
       "      <td>XK</td>\n",
       "      <td>G</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-05-14 20:15:00</td>\n",
       "      <td>2013-05-16 10:44:50</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>SYDA82546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   act_date             source  pos_ctry                          pos_iata  \\\n",
       "0  2013-03-05 00:00:00  1A      DE        a68dd7ae953c8acfb187a1af2dcbe123   \n",
       "1  2013-03-26 00:00:00  1A      US        e612b9eeeee6f17f42d9b0d3b79e75ca   \n",
       "2  2013-03-26 00:00:00  1A      US        e612b9eeeee6f17f42d9b0d3b79e75ca   \n",
       "3  2013-03-26 00:00:00  1A      AU        0f984b3bb6bd06661c95529bbd6193bc   \n",
       "4  2013-03-26 00:00:00  1A      AU        0f984b3bb6bd06661c95529bbd6193bc   \n",
       "\n",
       "                          pos_oid                      rloc            \\\n",
       "0  1a11ae49fcbf545fd2afc1a24d88d2b7  ea65900e72d71f4626378e2ebd298267   \n",
       "1  7437560d8f276d6d05eeb806d9e7edee  737295a86982c941f1c2da9a46a14043   \n",
       "2  7437560d8f276d6d05eeb806d9e7edee  737295a86982c941f1c2da9a46a14043   \n",
       "3  36472c6dbaf7afec9136ac40364e2794  5ecf00fdcbcec761c43dc7285253d0c1   \n",
       "4  36472c6dbaf7afec9136ac40364e2794  5ecf00fdcbcec761c43dc7285253d0c1   \n",
       "\n",
       "   cre_date             duration  distance  dep_port  ...  route            \\\n",
       "0  2013-02-22 00:00:00      1708         0  ZRH       ...  LHRZRH            \n",
       "1  2013-03-26 00:00:00    135270         0  SAL       ...  SALATLCLT         \n",
       "2  2013-03-26 00:00:00    135270         0  SAL       ...  CLTATLSAL         \n",
       "3  2013-03-26 00:00:00     30885         0  AKL       ...  AKLHKGSVO         \n",
       "4  2013-03-26 00:00:00     30885         0  AKL       ...  SVOHKGAKL         \n",
       "\n",
       "  carrier  bkg_class  cab_class  brd_time             off_time            pax  \\\n",
       "0      VI  T          Y          2013-03-07 08:50:00  2013-03-07 11:33:37  -1   \n",
       "1      NV  L          Y          2013-04-12 13:04:00  2013-04-12 22:05:40   1   \n",
       "2      NV  U          Y          2013-07-15 07:00:00  2013-07-15 11:34:51   1   \n",
       "3      XK  G          Y          2013-04-24 23:59:00  2013-04-25 16:06:31   1   \n",
       "4      XK  G          Y          2013-05-14 20:15:00  2013-05-16 10:44:50   1   \n",
       "\n",
       "   year month  oid        \n",
       "0  2013     3  NULL       \n",
       "1  2013     3  NULL       \n",
       "2  2013     3  NULL       \n",
       "3  2013     3  SYDA82546  \n",
       "4  2013     3  SYDA82546  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['act_date           ', 'source', 'pos_ctry', 'pos_iata', 'pos_oid  ',\n",
       "       'rloc          ', 'cre_date           ', 'duration', 'distance',\n",
       "       'dep_port', 'dep_city', 'dep_ctry', 'arr_port', 'arr_city', 'arr_ctry',\n",
       "       'lst_port', 'lst_city', 'lst_ctry', 'brd_port', 'brd_city', 'brd_ctry',\n",
       "       'off_port', 'off_city', 'off_ctry', 'mkt_port', 'mkt_city', 'mkt_ctry',\n",
       "       'intl', 'route          ', 'carrier', 'bkg_class', 'cab_class',\n",
       "       'brd_time           ', 'off_time           ', 'pax', 'year', 'month',\n",
       "       'oid      '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns seem to have a indefinite amount of white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['act_date', 'source', 'pos_ctry', 'pos_iata', 'pos_oid', 'rloc',\n",
       "       'cre_date', 'duration', 'distance', 'dep_port', 'dep_city', 'dep_ctry',\n",
       "       'arr_port', 'arr_city', 'arr_ctry', 'lst_port', 'lst_city', 'lst_ctry',\n",
       "       'brd_port', 'brd_city', 'brd_ctry', 'off_port', 'off_city', 'off_ctry',\n",
       "       'mkt_port', 'mkt_city', 'mkt_ctry', 'intl', 'route', 'carrier',\n",
       "       'bkg_class', 'cab_class', 'brd_time', 'off_time', 'pax', 'year',\n",
       "       'month', 'oid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.columns = [col.strip() for col in sample.columns]\n",
    "sample.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also get rid of he spaces in some columns using loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.loc[:,'arr_port'] = sample['arr_port'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could rename all columns using a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = {}\n",
    "for col in sample.columns:\n",
    "    new_cols[col] = col.strip()\n",
    "sample = sample.rename(new_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Count the number of lines in python for each file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do it as fast as possible we can select one column to count all lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bookings.csv has 10000010 lines.\n"
     ]
    }
   ],
   "source": [
    "bookings_lenght = len(pd.read_csv(\n",
    "                                  bookings_path,\n",
    "                                  compression='bz2', \n",
    "                                  sep= '^', \n",
    "                                  header=0, \n",
    "                                  usecols=['pax'], \n",
    "                                  ))\n",
    "print(f'Bookings.csv has {bookings_lenght} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Time', 'TxnCode', 'OfficeID', 'Country', 'Origin',\n",
       "       'Destination', 'RoundTrip', 'NbSegments', 'Seg1Departure',\n",
       "       'Seg1Arrival', 'Seg1Date', 'Seg1Carrier', 'Seg1BookingCode',\n",
       "       'Seg2Departure', 'Seg2Arrival', 'Seg2Date', 'Seg2Carrier',\n",
       "       'Seg2BookingCode', 'Seg3Departure', 'Seg3Arrival', 'Seg3Date',\n",
       "       'Seg3Carrier', 'Seg3BookingCode', 'Seg4Departure', 'Seg4Arrival',\n",
       "       'Seg4Date', 'Seg4Carrier', 'Seg4BookingCode', 'Seg5Departure',\n",
       "       'Seg5Arrival', 'Seg5Date', 'Seg5Carrier', 'Seg5BookingCode',\n",
       "       'Seg6Departure', 'Seg6Arrival', 'Seg6Date', 'Seg6Carrier',\n",
       "       'Seg6BookingCode', 'From', 'IsPublishedForNeg', 'IsFromInternet',\n",
       "       'IsFromVista', 'TerminalID', 'InternetOffice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches = pd.read_csv(\n",
    "                       searches_path,\n",
    "                       compression='bz2', \n",
    "                       sep= '^', \n",
    "                       header=0,\n",
    "                       nrows=10\n",
    "                       )\n",
    "searches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searches.csv has 20390198 lines.\n"
     ]
    }
   ],
   "source": [
    "searches_lenght = len(pd.read_csv(\n",
    "                                searches_path,\n",
    "                                compression='bz2', \n",
    "                                sep= '^', \n",
    "                                header=0, \n",
    "                                usecols=['Date'],\n",
    "                                ))\n",
    "print(f'searches.csv has {searches_lenght} lines.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Top 10 arrival airports in the world in 2013 (using the bookings file)\n",
    "\n",
    "• Arrival airport is the column **arr_port**. It is the IATA code for the airport\n",
    "\n",
    "• To get the total number of passengers for an airport, you can *sum* the column\n",
    "**pax**, grouping by **arr_port**. Note that there is negative pax. That corresponds to\n",
    "cancelations. So to get the total number of passengers that have actually\n",
    "booked, you should sum including the negatives (that will remove the canceled\n",
    "bookings).\n",
    "\n",
    "• Print the top 10 arrival airports in the standard output, including the number of\n",
    "passengers.\n",
    "\n",
    "• Bonus point: Get the name of the city or airport corresponding to that airport\n",
    "(programatically, we suggest to have a look at GeoBases in Github)\n",
    "\n",
    "• Bonus point: Solve this problem using pandas (instead of any other approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\n",
    "                     bookings_path,\n",
    "                     compression='bz2', \n",
    "                     sep= '^', \n",
    "                     header=0, \n",
    "                     usecols=['arr_port', 'pax', 'year'], \n",
    "                     #nrows = 100000\n",
    "                     chunksize=100_000 # con este parametro se convierte en un iterador\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-5ccdb752e80b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m with pd.read_csv(\n\u001b[0m\u001b[0;32m      2\u001b[0m                      \u001b[0mbookings_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                      \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bz2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                      \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'^'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                      \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: __enter__"
     ]
    }
   ],
   "source": [
    "with pd.read_csv(\n",
    "                     bookings_path,\n",
    "                     compression='bz2', \n",
    "                     sep= '^', \n",
    "                     header=0, \n",
    "                     usecols=['arr_port', 'pax', 'year'], \n",
    "                     #nrows = 100000\n",
    "                     chunksize=100_000 # con este parametro se convierte en un iterador\n",
    "                    ) as df_iter:\n",
    "                    for chunk in df_full:\n",
    "                        print(chunk.head(10))\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        arr_port  pax  year\n",
      "500000  VCE         1  2013\n",
      "500001  VCE         1  2013\n",
      "500002  VCE        -1  2013\n",
      "500003  VCE        -1  2013\n",
      "500004  VCE         1  2013\n",
      "500005  VCE         1  2013\n",
      "500006  YUL        -1  2013\n",
      "500007  YUL         1  2013\n",
      "500008  DPL        -1  2013\n",
      "500009  DPL         1  2013\n"
     ]
    }
   ],
   "source": [
    "for chunk in df_full:\n",
    "    print(chunk.head(10))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextFileReader' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-8b9f9d87272e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbookings_iter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'TextFileReader' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "print(bookings_iter.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-25596f055262>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m with pd.read_csv(\n\u001b[0m\u001b[0;32m      2\u001b[0m                 \u001b[0mbookings_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bz2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'^'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: __enter__"
     ]
    }
   ],
   "source": [
    "with pd.read_csv(\n",
    "                bookings_path,\n",
    "                compression='bz2', \n",
    "                sep= '^', \n",
    "                header=0, \n",
    "                usecols=['arr_port', 'pax', 'year'], \n",
    "                chunksize=100_000 # con este parametro se convierte en un iterador\n",
    "                ) as df_iter:\n",
    "    for chunk in df_iter:\n",
    "        print(chunk.head(10))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big.loc[:,'arr_port'] = df_big['arr_port'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_port</th>\n",
       "      <th>pax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>LHR</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>MCO</td>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>JFK</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>LAX</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>BKK</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>LAS</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>SFO</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>ORD</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>CDG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>DXB</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     arr_port   pax\n",
       "733       LHR  1006\n",
       "798       MCO   861\n",
       "620       JFK   795\n",
       "706       LAX   761\n",
       "156       BKK   747\n",
       "704       LAS   732\n",
       "1159      SFO   705\n",
       "957       ORD   686\n",
       "232       CDG   676\n",
       "366       DXB   587"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_big.groupby('arr_port')['pax'].sum().reset_index().sort_values(by='pax', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/GeoBases/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Plot the monthly number of searches for flights arriving at Málaga, Madrid or Barcelona\n",
    "\n",
    "• For the arriving airport, you can use the\n",
    "Destination column in the searches file.\n",
    "\n",
    "• Plot a curve for Málaga, another one for\n",
    "Madrid, and another one for Barcelona, in\n",
    "the same figure.\n",
    "\n",
    "• Bonus point: Solving this problem using\n",
    "pandas (instead of any other approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "Match searches with bookings\n",
    "\n",
    "• For every search in the searches file, find out whether\n",
    "the search ended up in a booking or not (using the info\n",
    "in the bookings file). For instance, search and booking\n",
    "origin and destination should match.\n",
    "\n",
    "• For the bookings file, origin and destination are the\n",
    "columns dep_port and arr_port, respectively.\n",
    "\n",
    "• Generate a CSV file with the search data, and an\n",
    "additional field, containing 1 if the search ended up in\n",
    "a booking, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5\n",
    "\n",
    "Write a Web Service\n",
    "\n",
    "• Wrap the output of the second exercise in a\n",
    "web service that returns the data in JSON\n",
    "format (instead of printing to the standard\n",
    "output).\n",
    "\n",
    "• The web service should accept a parameter\n",
    "n>0. For the top 10 airports, n is 10. For the X\n",
    "top airports, n is X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
