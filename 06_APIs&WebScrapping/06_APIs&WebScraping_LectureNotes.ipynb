{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can connect to public APIs and download data. This one corresponds to the international station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"timestamp\": 1654017813, \"iss_position\": {\"latitude\": \"-51.4371\", \"longitude\": \"171.4141\"}, \"message\": \"success\"}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get('http://api.open-notify.org/iss-now.json')\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert a json-formatted string such as the one we get in the response into a Python object with the json library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timestamp': 1654017813,\n",
       " 'iss_position': {'latitude': '-51.4371', 'longitude': '171.4141'},\n",
       " 'message': 'success'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = json.loads(response.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-51.4371'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['iss_position']['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'171.4141'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['iss_position']['longitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can go in the other direction and generate json-formatted strings from Python objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"name\": \"Dani\"}, {\"name\": \"Toni\"}]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profs = [{'name': 'Dani'}, {'name': 'Toni'}]\n",
    "json.dumps(profs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":\"jorge\",\"age\":62,\"count\":114531}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get('https://api.agify.io?name=jorge')\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age(name='Grandma'):\n",
    "    response = requests.get('https://api.agify.io?name='+name)\n",
    "    json_age = json.loads(response.text)['age']\n",
    "    return f'{name} is {json_age} years old.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Grandma is 72 years old.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'name': 'Jorge', 'country_id': 'ES'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"name\":\"jorge\",\"age\":46,\"count\":36357,\"country_id\":\"ES\"},{\"name\":\"Jorge\",\"age\":46,\"count\":36357,\"country_id\":\"ES\"}]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get('https://api.agify.io?name=jorge', params=parameters)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to read web pages (html) we need to use BeautifulSoup library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the articles on the front page os elpais.com (title and URL)\n",
    "\n",
    "Store it in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://elpais.com')\n",
    "soup = BeautifulSoup(response.text)\n",
    "articles = soup.findAll('article')\n",
    "\n",
    "titulares = []\n",
    "enlaces = []\n",
    "for a in articles:\n",
    "    # first we find all links on the front page\n",
    "    link = a.find('a', href=True)\n",
    "    enlaces.append(link['href'])\n",
    "    \n",
    "    # second we get the text from the respective class\n",
    "    titulo = a.find('h2', attrs={'class': 'c_t'})\n",
    "    titulares.append(titulo.text)\n",
    "\n",
    "    # after appending it to empty lists we just need to store it in a csv.\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'Titular':titulares, 'URL': enlaces})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('elpais.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a field in the csv that specifies if the article is premium or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://elpais.com')\n",
    "soup = BeautifulSoup(response.text)\n",
    "articles = soup.findAll('article')\n",
    "\n",
    "\n",
    "titulares = []\n",
    "enlaces = []\n",
    "premium = []\n",
    "for a in articles:\n",
    "    # first we find all links on the front page\n",
    "    link = a.find('a', href=True)\n",
    "    enlaces.append(link['href'])\n",
    "    \n",
    "    # second we get the text from the respective class\n",
    "    titulo = a.find('h2', attrs={'class': 'c_t'})\n",
    "    titulares.append(titulo.text)\n",
    " \n",
    "    # third, we look for a subcategory within the articles to determine if it is premium or not.\n",
    "    vip = a.find('span', attrs={'aria-label': 'Exclusivo suscriptores'})\n",
    "    premium.append(bool(vip))\n",
    "\n",
    "\n",
    "# after appending it to empty lists we just need to store it in a csv.\n",
    "\n",
    "df = pd.DataFrame({'Titular':titulares, 'URL': enlaces, 'Premium': premium})\n",
    "df.to_csv('elpais.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titular</th>\n",
       "      <th>URL</th>\n",
       "      <th>Premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sánchez se abre a prorrogar tres meses las ayu...</td>\n",
       "      <td>/espana/2022-05-31/sanchez-apunta-que-prorroga...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La Unión Europea pacta un rearme conjunto ante...</td>\n",
       "      <td>/internacional/2022-05-31/la-union-europea-pac...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El sexto golpe de las sanciones de la UE llega...</td>\n",
       "      <td>/internacional/2022-05-31/el-sexto-golpe-de-la...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alcaraz gana el tercer ‘set’ del partido y rec...</td>\n",
       "      <td>/deportes/2022-05-31/directo-zverev-alcaraz-en...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nadal contra Djokovic y sus dinámicas invertid...</td>\n",
       "      <td>/deportes/2022-05-31/nadal-contra-djokovic-y-s...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No pensar en lo que no se puede controlar</td>\n",
       "      <td>/deportes/2022-05-31/no-pensar-en-lo-que-no-se...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Código de honor y barbarie</td>\n",
       "      <td>https://elpais.com/opinion/editoriales/</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sumar gente o sumar partidos</td>\n",
       "      <td>/opinion/2022-05-31/sumar-gente-o-sumar-partid...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hasta los dientes</td>\n",
       "      <td>/opinion/2022-05-31/hasta-los-dientes.html</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14 Champions, 140 leyes</td>\n",
       "      <td>/opinion/2022-05-31/14-champions-140-leyes.html</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Al PSOE le conviene un Vox fuerte, a España no</td>\n",
       "      <td>/opinion/2022-05-31/al-psoe-le-conviene-un-vox...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sciammarella</td>\n",
       "      <td>/opinion/2022-05-31/sciammarella.html</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titular  \\\n",
       "0   Sánchez se abre a prorrogar tres meses las ayu...   \n",
       "1   La Unión Europea pacta un rearme conjunto ante...   \n",
       "2   El sexto golpe de las sanciones de la UE llega...   \n",
       "3   Alcaraz gana el tercer ‘set’ del partido y rec...   \n",
       "4   Nadal contra Djokovic y sus dinámicas invertid...   \n",
       "5           No pensar en lo que no se puede controlar   \n",
       "6                         Código de honor y barbarie    \n",
       "7                        Sumar gente o sumar partidos   \n",
       "8                                   Hasta los dientes   \n",
       "9                             14 Champions, 140 leyes   \n",
       "10     Al PSOE le conviene un Vox fuerte, a España no   \n",
       "11                                       Sciammarella   \n",
       "\n",
       "                                                  URL  Premium  \n",
       "0   /espana/2022-05-31/sanchez-apunta-que-prorroga...    False  \n",
       "1   /internacional/2022-05-31/la-union-europea-pac...    False  \n",
       "2   /internacional/2022-05-31/el-sexto-golpe-de-la...     True  \n",
       "3   /deportes/2022-05-31/directo-zverev-alcaraz-en...    False  \n",
       "4   /deportes/2022-05-31/nadal-contra-djokovic-y-s...    False  \n",
       "5   /deportes/2022-05-31/no-pensar-en-lo-que-no-se...     True  \n",
       "6             https://elpais.com/opinion/editoriales/    False  \n",
       "7   /opinion/2022-05-31/sumar-gente-o-sumar-partid...     True  \n",
       "8          /opinion/2022-05-31/hasta-los-dientes.html     True  \n",
       "9     /opinion/2022-05-31/14-champions-140-leyes.html     True  \n",
       "10  /opinion/2022-05-31/al-psoe-le-conviene-un-vox...     True  \n",
       "11              /opinion/2022-05-31/sciammarella.html    False  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\Usuario\\Desktop\\Master DATA SCIENCE\\06 APIs y web scrapping con Python\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "# webdriver.Firefox(executable_path=r'C:\\Users\\Usuario\\Desktop\\Master DATA SCIENCE\\06 APIs y web scrapping con Python\\geckodriver-v0.31.0-win32\\geckodriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://www.aflcio.org/Legislation-and-Politics/Legislative-Alerts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element_by_class_name('btn-load-more')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    button = driver.find_element_by_class_name('btn-load-more')\n",
    "    button.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look for every element in the class that fits best the container of the data we want to scrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'find_element_by_tag_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1f0bb713ab03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0malert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'content-details'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0malert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_tag_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'find_element_by_tag_name'"
     ]
    }
   ],
   "source": [
    "alert = driver.find_element_by_class_name('content-details')\n",
    "alert.find_element_by_tag_name('h2').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alert.find_element_by_tag_name('a').get_property('href')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annex: ultra easy scraping with pandas!\n",
    "\n",
    "When the data we want is already formatted as a table, we can do it even more easily! Just use `pandas.read_html`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "\n",
    "Extract the date of the worst aviation disaster from: https://en.wikipedia.org/wiki/List_of_accidents_and_disasters_by_death_toll\n",
    "\n",
    "Prerequisites: pandas, pd.read_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tables = pd.read_html('https://en.wikipedia.org/wiki/List_of_accidents_and_disasters_by_death_toll')\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tables[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Using Selenium, get the link to the video for Pasapalabra's \"Rosco\" of 2019-08-30.\n",
    "\n",
    "https://www.telecinco.es/pasapalabra/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\Usuario\\Desktop\\Master DATA SCIENCE\\06 APIs y web scrapping con Python\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.get('https://www.telecinco.es/pasapalabra/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to do it is the following.\n",
    "We set a range long enaugh for it to get to the page we look for.\n",
    "and compare dates in the elements of the page until we find the one we want and exit the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_date = \"30/08/2019\"\n",
    "for _ in range(1):\n",
    "    date = driver.find_elements_by_class_name('cards__postcard__content-1w21 ')\n",
    "    for element in date:\n",
    "        if ref_date == element.text[0:10]:\n",
    "            link = element.find_element('a')\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "    button = driver.find_element_by_class_name('pagination__pagination_viewmore-z9ko')\n",
    "    button.click()        \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other way is to define a function that looks for the date and start a while loop with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_date_present(date, driver):\n",
    "\n",
    "    date_texts = [element.text for element in driver.find_elements_by_class_name('cards__postcard__date_time-3Ach')]\n",
    "    \n",
    "    return any([date in text for text in date_texts])\n",
    "\n",
    "is_date_present('17/09/1955', driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not is_date_present('30/08/2019', driver):\n",
    "    button = driver.find_element_by_class_name('pagination__pagination_viewmore-z9ko')\n",
    "    button.click()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
